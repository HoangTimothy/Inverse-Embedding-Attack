# PhÃ¢n tÃ­ch Flow - Inverse Embedding Attack

## ğŸ¯ Ã tÆ°á»Ÿng chÃ­nh

### Váº¥n Ä‘á» cá»§a GEIA gá»‘c:
- Cáº§n data gá»‘c Ä‘á»ƒ train attacker
- KhÃ´ng thá»±c táº¿ trong real-world scenarios
- Metrics cao nhÆ°ng khÃ´ng practical

### Giáº£i phÃ¡p cá»§a chÃºng ta:
- **Transfer Learning**: Train trÃªn models tÆ°Æ¡ng tá»±, test trÃªn black-box
- **Cross-Model Attack**: KhÃ´ng cáº§n data gá»‘c cá»§a target model
- **Alignment Layers**: Xá»­ lÃ½ khÃ¡c biá»‡t embedding dimensions

## ğŸ”„ Flow chi tiáº¿t

### **Phase 1: Data Preparation**
```
Dataset â†’ Multiple Embedding Models â†’ Embeddings Storage
```

**Input:**
- Dataset: SST-2, PersonaChat, ABCD
- Embedding Models: 4 models khÃ¡c nhau
  - all-mpnet-base-v2 (768d)
  - stsb-roberta-base (768d) 
  - all-MiniLM-L6-v2 (384d)
  - paraphrase-MiniLM-L6-v2 (384d)

**Process:**
1. Load dataset tá»« HuggingFace/local
2. Extract embeddings tá»« má»—i model
3. Save embeddings + sentences pairs
4. Create alignment layers cho different dimensions

**Output:**
```
data/embeddings/
â”œâ”€â”€ sst2_train_all-mpnet-base-v2.json
â”œâ”€â”€ sst2_train_stsb-roberta-base.json
â”œâ”€â”€ sst2_train_all-MiniLM-L6-v2.json
â””â”€â”€ sst2_train_paraphrase-MiniLM-L6-v2.json
```

### **Phase 2: Attacker Training**
```
Embeddings â†’ Attacker Models â†’ Trained Attackers
```

**Input:**
- Embeddings tá»« 3 models (khÃ´ng pháº£i black-box)
- Attacker models: GPT-2, OPT, T5

**Process:**
1. Load embeddings cho tá»«ng model
2. Apply alignment náº¿u cáº§n
3. Train attacker models (dá»±a trÃªn GEIA framework)
4. Save trained models

**Output:**
```
models/
â”œâ”€â”€ attacker_gpt2_all-mpnet-base-v2/
â”œâ”€â”€ attacker_opt_stsb-roberta-base/
â””â”€â”€ attacker_t5_all-MiniLM-L6-v2/
```

### **Phase 3: Black-box Testing**
```
Black-box Embeddings â†’ Trained Attackers â†’ Recovered Text
```

**Input:**
- Black-box model (model thá»© 4)
- Test sentences
- Trained attackers

**Process:**
1. Generate embeddings tá»« black-box model
2. Apply alignment layers
3. Use trained attackers Ä‘á»ƒ generate text
4. Evaluate performance

**Output:**
```
experiments/results/
â””â”€â”€ blackbox_test_sst2_paraphrase-MiniLM-L6-v2.json
```

## ğŸ“Š Key Components

### **1. EmbeddingPreparer (`src/data_processing/prepare_embeddings.py`)**
```python
class EmbeddingPreparer:
    def load_embedding_models(self):
        # Load 4 embedding models
    
    def create_embeddings(self, sentences, model_name):
        # Generate embeddings for sentences
    
    def create_alignment_layers(self):
        # Create projection layers for dimension alignment
```

### **2. InverseEmbeddingAttacker (`src/attackers/train_attackers.py`)**
```python
class InverseEmbeddingAttacker:
    def train_on_batch(self, batch_embeddings, batch_sentences):
        # Training step (based on GEIA)
    
    def train(self, dataset_name, split='train'):
        # Complete training loop
```

### **3. BlackBoxTester (`src/evaluation/test_blackbox.py`)**
```python
class BlackBoxTester:
    def get_blackbox_embeddings(self, sentences):
        # Extract embeddings from black-box model
    
    def generate_text(self, embeddings, attacker_info):
        # Generate text using trained attackers
    
    def evaluate_attack(self, original, generated):
        # Calculate metrics
```

### **4. EmbeddingAlignment (`src/utils/alignment.py`)**
```python
class EmbeddingAlignment:
    def fit(self, source_embeddings, target_embeddings):
        # Learn alignment transformation
    
    def transform(self, embeddings):
        # Apply alignment
```

## ğŸ¯ Advantages over GEIA

### **1. Realistic Attack Scenario**
- âœ… KhÃ´ng cáº§n data gá»‘c cá»§a black-box
- âœ… Transfer learning approach
- âœ… Cross-model generalization

### **2. Practical Implementation**
- âœ… Reuse GEIA framework
- âœ… Modular design
- âœ… Easy to extend

### **3. Better Evaluation**
- âœ… Test on unseen models
- âœ… More realistic metrics
- âœ… Cross-domain evaluation

## ğŸš€ Usage Examples

### **Quick Start:**
```bash
# Install dependencies
pip install -r requirements.txt

# Run demo
python demo.py

# Run full experiment
python run_experiment.py --dataset sst2 --blackbox_model all-mpnet-base-v2
```

### **Step by Step:**
```bash
# 1. Prepare embeddings
python src/data_processing/prepare_embeddings.py --dataset sst2 --split train

# 2. Train attackers
python src/attackers/train_attackers.py --dataset sst2 --attacker gpt2 --embedding_model all-mpnet-base-v2

# 3. Test on black-box
python src/evaluation/test_blackbox.py --dataset sst2 --blackbox_model paraphrase-MiniLM-L6-v2
```

## ğŸ“ˆ Expected Results

### **Performance Metrics:**
- **Embedding Similarity**: 0.7-0.9
- **Exact Match Rate**: 0.1-0.3  
- **BLEU Score**: 0.5-0.8
- **Edit Distance**: 10-30 characters

### **Transfer Learning Effectiveness:**
- Better performance khi source vÃ  target models tÆ°Æ¡ng tá»±
- Degradation khi models khÃ¡c biá»‡t lá»›n
- Alignment layers giÃºp cáº£i thiá»‡n performance

## ğŸ”§ Technical Details

### **Alignment Methods:**
1. **Linear Regression**: ÄÆ¡n giáº£n, hiá»‡u quáº£
2. **PCA-based**: Cho high-dimensional embeddings
3. **Neural Alignment**: Cho complex transformations

### **Attacker Models:**
- **GPT-2**: Causal LM, tá»‘t cho text generation
- **OPT**: Open-source alternative
- **T5**: Seq2seq, cÃ³ thá»ƒ tá»‘t hÆ¡n cho structured text

### **Evaluation Metrics:**
- **Embedding Similarity**: Cosine similarity
- **Exact Match**: String comparison
- **BLEU Score**: N-gram overlap
- **Edit Distance**: Character-level difference

## ğŸ¯ Future Improvements

### **1. Advanced Alignment:**
- Multi-step alignment
- Adversarial alignment
- Domain-specific alignment

### **2. Better Attackers:**
- Ensemble methods
- Adversarial training
- Multi-modal attackers

### **3. Evaluation:**
- Human evaluation
- Semantic similarity
- Privacy metrics 