# Inverse Embedding Attack - Running Guide

## ğŸš€ Thá»© tá»± cháº¡y project

### **BÆ°á»›c 1: Chuáº©n bá»‹ mÃ´i trÆ°á»ng**
```bash
# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# Kiá»ƒm tra GPU (náº¿u cÃ³)
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

### **BÆ°á»›c 2: Chuáº©n bá»‹ datasets vÃ  embeddings**
```bash
# Chuáº©n bá»‹ táº¥t cáº£ datasets (SST-2, PersonaChat, ABCD)
# Má»—i dataset sáº½ cÃ³ 10,000 samples
python prepare_all_datasets.py
```

**Káº¿t quáº£:** Táº¡o ra 4 embedding datasets vá»›i 10,000 samples má»—i dataset:
- `sst2_train_all-mpnet-base-v2.json`
- `personachat_train_stsb-roberta-base.json` 
- `abcd_train_all-MiniLM-L6-v2.json`
- `sst2_train_paraphrase-MiniLM-L6-v2.json`

### **BÆ°á»›c 3: Train táº¥t cáº£ attackers**
```bash
# Train 3 attackers trÃªn 3 datasets khÃ¡c nhau
python train_all_attackers.py
```

**Káº¿t quáº£:** Train 3 attackers:
- GPT-2 attacker trÃªn SST-2 dataset
- OPT attacker trÃªn PersonaChat dataset  
- T5 attacker trÃªn ABCD dataset

### **BÆ°á»›c 4: Kiá»ƒm tra models Ä‘Ã£ train**
```bash
# Verify táº¥t cáº£ models Ä‘Ã£ Ä‘Æ°á»£c train thÃ nh cÃ´ng
python train_all_attackers.py --verify-only
```

### **BÆ°á»›c 5: Cháº¡y evaluation**
```bash
# Test attackers trÃªn black-box model
python src/evaluation/test_blackbox.py --dataset sst2 --split test --blackbox_model all-mpnet-base-v2
```

### **BÆ°á»›c 6: Xem káº¿t quáº£**
```bash
# Kiá»ƒm tra káº¿t quáº£ trong thÆ° má»¥c experiments/results/
ls experiments/results/
```

---

## ğŸ“‹ Chi tiáº¿t tá»«ng bÆ°á»›c

### **BÆ°á»›c 1: Chuáº©n bá»‹ mÃ´i trÆ°á»ng**

**Má»¥c Ä‘Ã­ch:** CÃ i Ä‘áº·t táº¥t cáº£ dependencies cáº§n thiáº¿t

**Kiá»ƒm tra:**
- âœ… Python 3.8+
- âœ… PyTorch vá»›i CUDA (náº¿u cÃ³ GPU)
- âœ… Transformers library
- âœ… Sentence Transformers
- âœ… Táº¥t cáº£ dependencies trong requirements.txt

### **BÆ°á»›c 2: Chuáº©n bá»‹ datasets**

**Má»¥c Ä‘Ã­ch:** Táº¡o 4 embedding datasets vá»›i 10,000 samples má»—i dataset

**QuÃ¡ trÃ¬nh:**
1. Load datasets tá»« HuggingFace (SST-2, PersonaChat, ABCD)
2. Láº¥y 10,000 samples tá»« má»—i dataset
3. Táº¡o embeddings báº±ng 4 embedding models khÃ¡c nhau
4. LÆ°u embeddings vÃ o file JSON

**Káº¿t quáº£ mong Ä‘á»£i:**
```
data/embeddings/
â”œâ”€â”€ sst2_train_all-mpnet-base-v2.json (10,000 samples)
â”œâ”€â”€ personachat_train_stsb-roberta-base.json (10,000 samples)
â”œâ”€â”€ abcd_train_all-MiniLM-L6-v2.json (10,000 samples)
â””â”€â”€ sst2_train_paraphrase-MiniLM-L6-v2.json (10,000 samples)
```

### **BÆ°á»›c 3: Train attackers**

**Má»¥c Ä‘Ã­ch:** Train 3 attacker models trÃªn 3 datasets khÃ¡c nhau

**Cáº¥u hÃ¬nh training:**
- **GPT-2 attacker:** Train trÃªn SST-2 dataset
- **OPT attacker:** Train trÃªn PersonaChat dataset
- **T5 attacker:** Train trÃªn ABCD dataset

**Tham sá»‘ training:**
- Epochs: 5
- Batch size: 8
- Learning rate: 2e-5
- Device: CUDA (náº¿u cÃ³) hoáº·c CPU

**Káº¿t quáº£ mong Ä‘á»£i:**
```
models/
â”œâ”€â”€ attacker_gpt2_all-mpnet-base-v2/
â”œâ”€â”€ attacker_opt_stsb-roberta-base/
â””â”€â”€ attacker_t5_all-MiniLM-L6-v2/
```

### **BÆ°á»›c 4: Verify models**

**Má»¥c Ä‘Ã­ch:** Kiá»ƒm tra táº¥t cáº£ models Ä‘Ã£ Ä‘Æ°á»£c train thÃ nh cÃ´ng

**Kiá»ƒm tra:**
- âœ… Model files tá»“n táº¡i
- âœ… Projection layers Ä‘Æ°á»£c lÆ°u
- âœ… Tokenizers Ä‘Æ°á»£c lÆ°u
- âœ… Config files Ä‘Æ°á»£c lÆ°u

### **BÆ°á»›c 5: Evaluation**

**Má»¥c Ä‘Ã­ch:** Test attackers trÃªn black-box model

**QuÃ¡ trÃ¬nh:**
1. Load trained attackers
2. Load test dataset
3. Generate text tá»« embeddings
4. TÃ­nh similarity vá»›i original text
5. ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng text

**Metrics:**
- Embedding similarity (cosine similarity)
- Text quality (length, diversity)
- Semantic similarity

### **BÆ°á»›c 6: Káº¿t quáº£**

**Má»¥c Ä‘Ã­ch:** Xem vÃ  phÃ¢n tÃ­ch káº¿t quáº£

**Files káº¿t quáº£:**
```
experiments/results/
â”œâ”€â”€ blackbox_attack_results.json
â”œâ”€â”€ similarity_scores.json
â””â”€â”€ text_quality_metrics.json
```

---

## âš ï¸ LÆ°u Ã½ quan trá»ng

### **Thá»i gian cháº¡y:**
- **BÆ°á»›c 2:** ~30-60 phÃºt (tÃ¹y GPU)
- **BÆ°á»›c 3:** ~2-4 giá» (tÃ¹y GPU vÃ  model size)
- **BÆ°á»›c 5:** ~15-30 phÃºt

### **YÃªu cáº§u pháº§n cá»©ng:**
- **RAM:** Tá»‘i thiá»ƒu 16GB
- **GPU:** Khuyáº¿n nghá»‹ cÃ³ GPU (8GB+ VRAM)
- **Storage:** Tá»‘i thiá»ƒu 10GB free space

### **Xá»­ lÃ½ lá»—i:**
- Náº¿u GPU out of memory: Giáº£m batch_size
- Náº¿u training cháº­m: TÄƒng learning_rate
- Náº¿u dataset loading lá»—i: Kiá»ƒm tra internet connection

---

## ğŸ”§ Troubleshooting

### **Lá»—i thÆ°á»ng gáº·p:**

1. **CUDA out of memory:**
   ```bash
   # Giáº£m batch size trong config.py
   TRAIN_CONFIG['batch_size'] = 4  # Thay vÃ¬ 8
   ```

2. **Dataset loading failed:**
   ```bash
   # Kiá»ƒm tra internet connection
   # Thá»­ láº¡i prepare_all_datasets.py
   ```

3. **Model loading failed:**
   ```bash
   # Kiá»ƒm tra model path
   # Äáº£m báº£o model Ä‘Ã£ Ä‘Æ°á»£c train thÃ nh cÃ´ng
   ```

### **Kiá»ƒm tra tiáº¿n trÃ¬nh:**
```bash
# Xem logs
tail -f logs/training.log

# Kiá»ƒm tra GPU usage
nvidia-smi

# Kiá»ƒm tra disk space
df -h
```

---

## ğŸ“Š Expected Results

### **Sau khi hoÃ n thÃ nh:**

1. **4 embedding datasets** vá»›i 10,000 samples má»—i dataset
2. **3 trained attackers** (GPT-2, OPT, T5)
3. **Black-box evaluation results** vá»›i similarity scores
4. **Complete research pipeline** sáºµn sÃ ng cho publication

### **Success metrics:**
- âœ… Táº¥t cáº£ datasets Ä‘Æ°á»£c táº¡o thÃ nh cÃ´ng
- âœ… Táº¥t cáº£ attackers Ä‘Æ°á»£c train thÃ nh cÃ´ng  
- âœ… Similarity scores > 0.7 (tá»‘t)
- âœ… Text quality metrics Ä‘áº¡t chuáº©n

---

## ğŸ¯ Next Steps

Sau khi hoÃ n thÃ nh pipeline:

1. **Analyze results** - PhÃ¢n tÃ­ch káº¿t quáº£ chi tiáº¿t
2. **Compare with baselines** - So sÃ¡nh vá»›i baseline methods
3. **Write paper** - Viáº¿t research paper
4. **Submit to conference** - Submit Ä‘áº¿n conference/journal

---

**ğŸ‰ ChÃºc báº¡n thÃ nh cÃ´ng vá»›i research project!**

## ğŸ¯ Test vá»›i Google Colab

### 1. Clone repository
```python
!git clone <your-repo-url>
%cd Inverse-Embedding-Attack
```

### 2. Install dependencies
```python
!pip install -r requirements.txt
!pip install tf-keras
```

### 3. Run quick test
```python
!python quick_test.py
```

### 4. Run full experiment
```python
!python run_experiment.py --dataset sst2 --blackbox_model all-mpnet-base-v2
```

## ğŸ“Š Expected Results

### Demo Results:
- Embedding extraction: âœ…
- Alignment: âœ…
- Attack simulation: âœ…
- Complete flow: âœ…

### Full Experiment Results:
- Embedding similarity: 0.7-0.9
- Exact match rate: 0.1-0.3
- BLEU score: 0.5-0.8

## ğŸ” Debug Tips

### 1. Check GPU availability
```python
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}")
```

### 2. Check model loading
```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-mpnet-base-v2')
print("Model loaded successfully")
```

### 3. Check data loading
```python
from datasets import load_dataset
dataset = load_dataset('glue', 'sst2', split='train[:10]')
print(f"Loaded {len(dataset)} samples")
```

## ğŸ“ File Structure
```
Inverse_Embedding_Attack/
â”œâ”€â”€ config.py                    # Configuration
â”œâ”€â”€ demo.py                      # Demo script
â”œâ”€â”€ quick_test.py               # Quick test
â”œâ”€â”€ test_simple.py              # Detailed test
â”œâ”€â”€ run_experiment.py           # Full experiment
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ RUNNING_GUIDE.md           # This file
â””â”€â”€ src/
    â”œâ”€â”€ data_processing/
    â”‚   â””â”€â”€ prepare_embeddings.py
    â”œâ”€â”€ attackers/
    â”‚   â”œâ”€â”€ train_attackers.py
    â”‚   â”œâ”€â”€ attacker_models.py
    â”‚   â””â”€â”€ decode_beam_search.py
    â”œâ”€â”€ evaluation/
    â”‚   â””â”€â”€ test_blackbox.py
    â””â”€â”€ utils/
        â””â”€â”€ alignment.py
```

## ğŸ†˜ Need Help?

Náº¿u gáº·p lá»—i, hÃ£y:

1. Cháº¡y `python quick_test.py` Ä‘á»ƒ kiá»ƒm tra components
2. Cháº¡y `python test_simple.py` Ä‘á»ƒ test chi tiáº¿t
3. Kiá»ƒm tra logs vÃ  error messages
4. Äáº£m báº£o Ä‘Ã£ cÃ i Ä‘Ãºng dependencies
5. Kiá»ƒm tra GPU/CPU compatibility 